<!DOCTYPE html>
<html lang="en"><head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title> | Glen Berseth</title>
    <link rel="canonical" href="/blog/2019/10/12/CCRIG.html">
    

    <meta property="og:title" content="">
    <meta property="og:url" content="/blog/2019/10/12/CCRIG.html">
    <meta property="og:site_name" content="Glen Berseth">
    <meta name="twitter:card" content="summary">
    <meta property="twitter:title" content="">

	<script type="text/javascript" id="MathJax-script" async
	  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
	</script>
    <script type="application/ld+json">
    {"@type":"WebSite","headline":"Glen Berseth","url":"/","name":"Glen Berseth","@context":"https://schema.org"}</script>
    <!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css">
    <!-- <link rel="stylesheet" href="/assets/main.css"> --></head>
<body><header class="site-header">

    <div class="wrapper"><a class="site-title" rel="author" href="/">Glen Berseth</a><nav class="site-nav">
            <input type="checkbox" id="nav-trigger" class="nav-trigger" />
            <label for="nav-trigger">
                <span class="menu-icon">
                    <svg viewBox="0 0 18 15" width="18px" height="15px">
                        <path d="M1.5 1.5 h15 M1.5 7.5 h15 M1.5 13.5 h15" stroke="black" stroke-width="3" stroke-linecap="round" />
                      </svg>
                </span>
            </label>

            <div class="trigger">
                    <a class="page-link" href="/">Home</a>
                
                    <a class="page-link" href="/people/">People</a>
                
                    <a class="page-link" href="/publications/">Publications</a>
                
                    <a class="page-link" href="/join/">Join Us</a>
                
                    <a class="page-link" href="/posts/">Posts</a>
                
                    <a class="page-link" href="/teaching/">Teaching</a>
                
                <a class="page-link" href="/fr/blog/2019/10/12/CCRIG.html">Fr</a>
                
            </div>
        </nav></div>
    
</header>
<main class="page-content" aria-label="Content">
        <div class="wrapper">
            <article class="post">

    <header class="post-header">
        <h1 class="post-title"></h1>
    </header>
    <div class="post-content">
        <div align="center">
	<p>
				Ashvin Nair*, Shikhar Bahl*, Alexander Khazatsky*, Vitchyr Pong, Glen Berseth, Sergey Levine
	</p>
	<p>	
            University of California, Berkeley
    </p>
    <p>	
            * Equal Contribution
    </p>
</div>

<center>

</center>

<div align="center">
            <img width="300" src="/assets/projects/CCRIG/method_step1.png" /> <img width="300" src="/assets/projects/CCRIG/cc_vae.png" />
</div>

<p>While reinforcement learning provides an appealing formalism for learning individual skills, a general-purpose robotic system must be able to master an extensive repertoire of behaviors. Instead of learning a large collection of skills individually, can we instead enable a robot to propose and practice its own behaviors automatically, learning about the affordances and behaviors that it can perform in its environment, such that it can then repurpose this knowledge once a new task is commanded by the user? In this paper, we study this question in the context of self-supervised goal-conditioned reinforcement learning. A central challenge in this learning regime is the problem of goal setting: in order to practice useful skills, the robot must be able to autonomously set goals that are feasible but diverse. When the robot’s environment and available objects vary, as they do in most open-world settings, the robot must propose to itself only those goals that it can accomplish in its present setting with the objects that are at hand. Previous work only studies self-supervised goal-conditioned RL in a single-environment setting, where goal proposals come from the robot’s past experience or a generative model are sufficient. In more diverse settings, this frequently leads to impossible goals and, as we show experimentally, prevents effective learning. We propose a conditional goal-setting model that aims to propose goals that are feasible from the robot’s current state. We demonstrate that this enables self-supervised goal-conditioned off-policy learning with raw image observations in the real world, enabling a robot to manipulate a variety of objects and generalize to new objects that were not seen during training.</p>

<h2 id="files">Files</h2>

<p><a href="https://arxiv.org/abs/1910.11670">Paper</a></p>

<h3 id="bibtex">Bibtex</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{nair19ccrig,
    author    = {A. Nair and S. Bahl and A. Khazatsky and V. Pong and G. Berseth and S. Levine},
    title     = {Contextual Imagined Goals for Self-Supervised Robotic Learning},
    booktitle = {Conference on Robot Learning (CoRL)},
    year      = {2019}
} 
</code></pre></div></div>

    </div>

</article>
        </div>
    </main><footer class="site-footer h-card">
    <data class="u-url" href="/%20/"></data>

    <div class="wrapper">
        

        <div class="footer-col-wrapper">
            <div class="footer-col footer-col-1">
                <ul class="contact-list">
                    <li class="p-name">Glen Berseth</li></ul>
            </div>

            <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/neo-x"><svg
                class="svg-icon">
                <use xlink:href="/assets/minima-social-icons.svg#github"></use>
            </svg> <span class="username">neo-x</span></a></li><li><a
            href="https://www.linkedin.com/in/glen-berseth-0523278b"><svg class="svg-icon">
                <use xlink:href="/assets/minima-social-icons.svg#linkedin"></use>
            </svg> <span class="username">glen-berseth-0523278b</span></a></li><li><a
            href="https://www.twitter.com/GlenBerseth"><svg class="svg-icon">
                <use xlink:href="/assets/minima-social-icons.svg#twitter"></use>
            </svg> <span class="username">GlenBerseth</span></a></li><li><a rel="me"
            href="https://www.youtube.com/channel/UCOouaBg4gHIlNvPkJn_8ooA"
            title="Real Lab"><svg class="svg-icon grey">
                <use xlink:href="/assets/minima-social-icons.svg#youtube"></use>
            </svg> <span class="username">Real Lab</span></a></li></ul></div>

            <div class="footer-col footer-col-3">
                <p>I (he/him/il) am an assistant professor at the University de Montreal and Mila. My research explores how to use deep learning and reinforcement learning to develop generalist robots.</p>
            </div>
        </div>

    </div>

</footer></body>

</html>