@inproceedings{
jain2025nonadversarial,
title={Non-Adversarial Inverse Reinforcement Learning via Successor Feature Matching},
author={Arnav Kumar Jain and Harley Wiltzer and Jesse Farebrother and Irina Rish and Glen Berseth and Sanjiban Choudhury},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=LvRQgsvd5V}
}

@inproceedings{
riemer2024realtime,
title={Realtime Reinforcement Learning: Towards Rapid Asynchronous Deployment of Large Models},
author={Matthew Riemer and Gopeshh Subbaraj and Glen Berseth and Irina Rish},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=fXb9BbuyAD}
}

@inproceedings{
przystupa2024minimally,
title={Minimally Invasive Morphology Adaptation via Parameter Efficient Fine-Tuning},
author={Michael Przystupa and Hongyao Tang and Mariano Phielipp and Santiago Miret and Martin J{\"a}gersand and Glen Berseth},
booktitle={[CoRL 2024] Morphology-Aware Policy and Design Learning Workshop (MAPoDeL)},
year={2024},
url={https://openreview.net/forum?id=kvkC88H3Oi}
}

@misc{yuan2024rlexploreacceleratingresearchintrinsicallymotivated,
      title={RLeXplore: Accelerating Research in Intrinsically-Motivated Reinforcement Learning}, 
      author={Mingqi Yuan and Roger Creus Castanyer and Bo Li and Xin Jin and Glen Berseth and Wenjun Zeng},
      year={Preprint},
      eprint={2405.19548},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.19548}, 
}

@inproceedings{sun2024enhancingagentlearningworld,
      title={Enhancing Agent Learning through World Dynamics Modeling}, 
      author={Zhiyuan Sun and Haochen Shi and Marc-Alexandre Côté and Glen Berseth and Xingdi Yuan and Bang Liu},
      year={2024},
      eprint={2407.17695},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.17695}, 
	booktitle={The 2024 Conference on Empirical Methods in Natural Language Processing},
	year={2024},
	url={https://openreview.net/forum?id=tepFqIdrJU},
}

@inproceedings{venkatraman2024amortizing,
      title={Amortizing intractable inference in diffusion models for vision, language, and control}, 
      author={Siddarth Venkatraman and Moksh Jain and Luca Scimeca and Minsu Kim and Marcin Sendera and Mohsin Hasan and Luke Rowe and Sarthak Mittal and Pablo Lemos and Emmanuel Bengio and Alexandre Adam and Jarrid Rector-Brooks and Yoshua Bengio and Glen Berseth and Nikolay Malkin},
      year={2024},
      eprint={2405.20971},
      archivePrefix={arXiv},
      primaryClass={id='cs.LG' full_name='Machine Learning' is_active=True alt_name=None in_archive='cs' is_general=False description='Papers on all aspects of machine learning research (supervised, unsupervised, reinforcement learning, bandit problems, and so on) including also robustness, explanation, fairness, and methodology. cs.LG is also an appropriate primary category for applications of machine learning methods.'},
      image={/img/papers/rtb.png},
 publisher = {Curran Associates, Inc.},
  booktitle = {Advances in Neural Information Processing Systems},
 year = {2024},
url={https://openreview.net/forum?id=gVTkMsaaGI},
}

@article{open_x_embodiment_rt_x_2023,
title={Open {X-E}mbodiment: Robotic Learning Datasets and {RT-X} Models (ICRA2024 best paper)},
author = {Open X-Embodiment Collaboration and Abby O'Neill and Abdul Rehman and Abhiram Maddukuri and Abhishek Gupta and Abhishek Padalkar and Abraham Lee and Acorn Pooley and Agrim Gupta and Ajay Mandlekar and Ajinkya Jain and Albert Tung and Alex Bewley and Alex Herzog and Alex Irpan and Alexander Khazatsky and Anant Rai and Anchit Gupta and Andrew Wang and Anikait Singh and Animesh Garg and Aniruddha Kembhavi and Annie Xie and Anthony Brohan and Antonin Raffin and Archit Sharma and Arefeh Yavary and Arhan Jain and Ashwin Balakrishna and Ayzaan Wahid and Ben Burgess-Limerick and Beomjoon Kim and Bernhard Schölkopf and Blake Wulfe and Brian Ichter and Cewu Lu and Charles Xu and Charlotte Le and Chelsea Finn and Chen Wang and Chenfeng Xu and Cheng Chi and Chenguang Huang and Christine Chan and Christopher Agia and Chuer Pan and Chuyuan Fu and Coline Devin and Danfei Xu and Daniel Morton and Danny Driess and Daphne Chen and Deepak Pathak and Dhruv Shah and Dieter Büchler and Dinesh Jayaraman and Dmitry Kalashnikov and Dorsa Sadigh and Edward Johns and Ethan Foster and Fangchen Liu and Federico Ceola and Fei Xia and Feiyu Zhao and Freek Stulp and Gaoyue Zhou and Gaurav S. Sukhatme and Gautam Salhotra and Ge Yan and Gilbert Feng and Giulio Schiavi and Glen Berseth and Gregory Kahn and Guanzhi Wang and Hao Su and Hao-Shu Fang and Haochen Shi and Henghui Bao and Heni Ben Amor and Henrik I Christensen and Hiroki Furuta and Homer Walke and Hongjie Fang and Huy Ha and Igor Mordatch and Ilija Radosavovic and Isabel Leal and Jacky Liang and Jad Abou-Chakra and Jaehyung Kim and Jaimyn Drake and Jan Peters and Jan Schneider and Jasmine Hsu and Jeannette Bohg and Jeffrey Bingham and Jeffrey Wu and Jensen Gao and Jiaheng Hu and Jiajun Wu and Jialin Wu and Jiankai Sun and Jianlan Luo and Jiayuan Gu and Jie Tan and Jihoon Oh and Jimmy Wu and Jingpei Lu and Jingyun Yang and Jitendra Malik and João Silvério and Joey Hejna and Jonathan Booher and Jonathan Tompson and Jonathan Yang and Jordi Salvador and Joseph J. Lim and Junhyek Han and Kaiyuan Wang and Kanishka Rao and Karl Pertsch and Karol Hausman and Keegan Go and Keerthana Gopalakrishnan and Ken Goldberg and Kendra Byrne and Kenneth Oslund and Kento Kawaharazuka and Kevin Black and Kevin Lin and Kevin Zhang and Kiana Ehsani and Kiran Lekkala and Kirsty Ellis and Krishan Rana and Krishnan Srinivasan and Kuan Fang and Kunal Pratap Singh and Kuo-Hao Zeng and Kyle Hatch and Kyle Hsu and Laurent Itti and Lawrence Yunliang Chen and Lerrel Pinto and Li Fei-Fei and Liam Tan and Linxi "Jim" Fan and Lionel Ott and Lisa Lee and Luca Weihs and Magnum Chen and Marion Lepert and Marius Memmel and Masayoshi Tomizuka and Masha Itkina and Mateo Guaman Castro and Max Spero and Maximilian Du and Michael Ahn and Michael C. Yip and Mingtong Zhang and Mingyu Ding and Minho Heo and Mohan Kumar Srirama and Mohit Sharma and Moo Jin Kim and Naoaki Kanazawa and Nicklas Hansen and Nicolas Heess and Nikhil J Joshi and Niko Suenderhauf and Ning Liu and Norman Di Palo and Nur Muhammad Mahi Shafiullah and Oier Mees and Oliver Kroemer and Osbert Bastani and Pannag R Sanketi and Patrick "Tree" Miller and Patrick Yin and Paul Wohlhart and Peng Xu and Peter David Fagan and Peter Mitrano and Pierre Sermanet and Pieter Abbeel and Priya Sundaresan and Qiuyu Chen and Quan Vuong and Rafael Rafailov and Ran Tian and Ria Doshi and Roberto Mart{'i}n-Mart{'i}n and Rohan Baijal and Rosario Scalise and Rose Hendrix and Roy Lin and Runjia Qian and Ruohan Zhang and Russell Mendonca and Rutav Shah and Ryan Hoque and Ryan Julian and Samuel Bustamante and Sean Kirmani and Sergey Levine and Shan Lin and Sherry Moore and Shikhar Bahl and Shivin Dass and Shubham Sonawani and Shuran Song and Sichun Xu and Siddhant Haldar and Siddharth Karamcheti and Simeon Adebola and Simon Guist and Soroush Nasiriany and Stefan Schaal and Stefan Welker and Stephen Tian and Subramanian Ramamoorthy and Sudeep Dasari and Suneel Belkhale and Sungjae Park and Suraj Nair and Suvir Mirchandani and Takayuki Osa and Tanmay Gupta and Tatsuya Harada and Tatsuya Matsushima and Ted Xiao and Thomas Kollar and Tianhe Yu and Tianli Ding and Todor Davchev and Tony Z. Zhao and Travis Armstrong and Trevor Darrell and Trinity Chung and Vidhi Jain and Vincent Vanhoucke and Wei Zhan and Wenxuan Zhou and Wolfram Burgard and Xi Chen and Xiaolong Wang and Xinghao Zhu and Xinyang Geng and Xiyuan Liu and Xu Liangwei and Xuanlin Li and Yao Lu and Yecheng Jason Ma and Yejin Kim and Yevgen Chebotar and Yifan Zhou and Yifeng Zhu and Yilin Wu and Ying Xu and Yixuan Wang and Yonatan Bisk and Yoonyoung Cho and Youngwoon Lee and Yuchen Cui and Yue Cao and Yueh-Hua Wu and Yujin Tang and Yuke Zhu and Yunchu Zhang and Yunfan Jiang and Yunshuang Li and Yunzhu Li and Yusuke Iwasawa and Yutaka Matsuo and Zehan Ma and Zhuo Xu and Zichen Jeff Cui and Zichen Zhang and Zipeng Lin},
howpublished  = {\url{https://arxiv.org/abs/2310.08864}},
year = {2024},
journal={International Conference on Robotics and Automation (ICRA 2024)},
projectpage={https://robotics-transformer-x.github.io/},
eprint={2310.08864},
archivePrefix={arXiv},
url={https://openreview.net/forum?id=E0LWTN1xPX},
code = {https://github.com/google-deepmind/open_x_embodiment},
teaser_video={https://robotics-transformer-x.github.io/video/teaser_compressed.mp4},
}

@inproceedings{tang2024improving,
  title={Improving Deep Reinforcement Learning by Reducing the Chain Effect of Value and Policy Churn},
  author={Tang, Hongyao and Berseth, Glen },
 publisher = {Curran Associates, Inc.},
  booktitle = {Advances in Neural Information Processing Systems},
 year = {2024},
      eprint={2409.04792},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.04792}, 
}

@inproceedings{Hugessen2024simpICRL,
  title={Simplifying Constraint Inference with Inverse Reinforcement Learning},
  author={Hugessen, Adriana and  Wiltzer, Harley and Berseth, Glen},
 publisher = {Curran Associates, Inc.},
  booktitle = {Advances in Neural Information Processing Systems},
 year = {2024},
url={https://openreview.net/forum?id=T5Cerv7PT2}
}

@inproceedings{khazatsky2024droid,
      title={DROID: A Large-Scale In-The-Wild Robot Manipulation Dataset}, 
      author={Alexander Khazatsky and Karl Pertsch and Suraj Nair and Ashwin Balakrishna and Sudeep Dasari and Siddharth Karamcheti and Soroush Nasiriany and Mohan Kumar Srirama and Lawrence Yunliang Chen and Kirsty Ellis and Peter David Fagan and Joey Hejna and Masha Itkina and Marion Lepert and Yecheng Jason Ma and Patrick Tree Miller and Jimmy Wu and Suneel Belkhale and Shivin Dass and Huy Ha and Arhan Jain and Abraham Lee and Youngwoon Lee and Marius Memmel and Sungjae Park and Ilija Radosavovic and Kaiyuan Wang and Albert Zhan and Kevin Black and Cheng Chi and Kyle Beltran Hatch and Shan Lin and Jingpei Lu and Jean Mercat and Abdul Rehman and Pannag R Sanketi and Archit Sharma and Cody Simpson and Quan Vuong and Homer Rich Walke and Blake Wulfe and Ted Xiao and Jonathan Heewon Yang and Arefeh Yavary and Tony Z. Zhao and Christopher Agia and Rohan Baijal and Mateo Guaman Castro and Daphne Chen and Qiuyu Chen and Trinity Chung and Jaimyn Drake and Ethan Paul Foster and Jensen Gao and David Antonio Herrera and Minho Heo and Kyle Hsu and Jiaheng Hu and Donovon Jackson and Charlotte Le and Yunshuang Li and Kevin Lin and Roy Lin and Zehan Ma and Abhiram Maddukuri and Suvir Mirchandani and Daniel Morton and Tony Nguyen and Abigail O'Neill and Rosario Scalise and Derick Seale and Victor Son and Stephen Tian and Emi Tran and Andrew E. Wang and Yilin Wu and Annie Xie and Jingyun Yang and Patrick Yin and Yunchu Zhang and Osbert Bastani and Glen Berseth and Jeannette Bohg and Ken Goldberg and Abhinav Gupta and Abhishek Gupta and Dinesh Jayaraman and Joseph J Lim and Jitendra Malik and Roberto Martín-Martín and Subramanian Ramamoorthy and Dorsa Sadigh and Shuran Song and Jiajun Wu and Michael C. Yip and Yuke Zhu and Thomas Kollar and Sergey Levine and Chelsea Finn},year={2024},
      eprint={2403.12945},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      booktitle={Robotics: Science and Systems XX, 2024},
      video={https://www.youtube.com/watch?v=xqCJkTjAXDE},
      projectpage={https://droid-dataset.github.io/},
      url={https://droid-dataset.github.io/},
      teaser_video={https://droid-dataset.github.io/videos/droid_teaser_animated.mp4},
}

@article{HuggensonSurpriseAdapt,
  title={	
Surprise-Adaptive Intrinsic Motivation for Unsupervised Reinforcement Learning},
  author={Adriana Knatchbull-Hugessen and Roger Creus-Castanyer and Faisal Mohamed and Glen Berseth},
  year={2024},
  primaryClass={cs.LG},
  journal   = {Reinforcement Learning Conference 2024},
  url={https://openreview.net/forum?id=E0LWTN1xPX},
  image={/img/papers/s-adapt.png},
}

@article{li2024reinforcement,
      title={Reinforcement Learning for Versatile, Dynamic, and Robust Bipedal Locomotion Control}, 
      author={Zhongyu Li and Xue Bin Peng and Pieter Abbeel and Sergey Levine and Glen Berseth and Koushil Sreenath},
      year={2024},
      arxiv={2401.16889},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      journal   = {International Journal of Robotics Research},
      video={youtu.be/sQEnDbET75g},
      image={/img/papers/robust-cassie.png},
}

@inproceedings{CreusSOFE2023,
  title={	
Improving Intrinsic Exploration by Creating Stationary Objectives},
  author={Roger Creus Castanyer and Joshua Romoff and Glen Berseth},
      arxiv={2310.18144},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=YbZxT0SON4},
image={/img/papers/sofe.png}

}

@inproceedings{Ghugarem2023,
  title={	
Closing the Gap between {TD} Learning and Supervised Learning - A Generalisation Point of View},
  author={Raj Ghugare and Matthieu Geist and Benjamin Eysenbach and Glen Berseth},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=qg5JENs0N4},
 arxiv={2401.11237},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      image={/img/papers/stitching.png},
}
x
@article{DEMOIS,
  author    = {Charlie Gauthier and Florian Golemo and Glen Berseth and Liam Paull},
  title     = {Fearful Goal Generation for Robust Policy Learning},
  journal   = {CoRL 2022 workshop on Learning for Agile Robotics},
  url={https://openreview.net/forum?id=3cxan6Ygrv},
  year={PrePrint}
}

@article{DemeuleInariant,
  title={	
Adaptive Resolution Residual Networks},
  author={L{\'e}a Demeule and Mahtab Sandhu, and Glen Berseth},
 publisher = {Curran Associates, Inc.},
  journal = {The Symbiosis of Deep Learning and Differential Equations III - a NeurIPS2023 workshop (Oral)},
  year={Preprint},
  url={https://openreview.net/forum?id=9hcsB4oYxG}
}

@inproceedings{PatilTABA,
  title={	
Intelligent Switching for Reset-Free {RL}},
  author={Darshan Patil and Janarthanan Rajendran and Glen Berseth and Sarath Chandar},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=Nq45xeghcL},
image={/img/papers/RISC.png},
}

@inproceedings{MadanGFNGCRL,
  title={Towards Improving Exploration through Sibling Augmented {GF}lowNets},
  author={Kanika Madan and Alex Lamb and Emmanuel Bengio and Glen Berseth and Yoshua Bengio},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025},
  url={https://openreview.net/forum?id=HH4KWP8RP5},
  image={/img/papers/gfn-siblingNets.png},
}


@inproceedings{GhugaremChemRL,
  title={	
Searching the space of high-value molecules using reinforcement learning and language models},
  author={Raj Ghugare and Santiago Miret and Adriana Hugessen and Mariano Phielipp and Glen Berseth},
  arxiv={2310.02902},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=nqlymMx42E},
image={/img/papers/chemrl.png},
projectpage = {https://chemrlformer.github.io/}
}

@inproceedings{VenkatramanDiffuSkill,
      title={Reasoning with Latent Diffusion in Offline Reinforcement Learning}, 
      author={Siddarth Venkatraman and Shivesh Khaitan and Ravi Tej Akella and John Dolan and Jeff Schneider and Glen Berseth},
      arxiv={2309.06599},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=tGQirjzddO},
image={/img/papers/ldcq.png}
}

@inproceedings{jain2023maximum,
    title={Maximum State Entropy Exploration using Predecessor and Successor Representations},
    author={Arnav Kumar Jain and Lucas Lehnert and Irina Rish and Glen Berseth},
    year={2023},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    arxiv={2306.14808},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023},
    url={https://openreview.net/forum?id=tFsxtqGmkn},
    image={/img/papers/Jain23.png}
}

@inproceedings{gao2023bootstrapping,
      title={Bootstrapping Adaptive Human-Machine Interfaces with Offline Reinforcement Learning}, 
      author={Jensen Gao and Siddharth Reddy and Glen Berseth and Anca D. Dragan and Sergey Levine},
      year={2023},
      arxiv={2309.03839},
  booktitle = {Proc. IEEE/RSJ Intl Conf on Intelligent Robots and Systems (IROS 2023)},
  arxiv = {2208.01160},
  projectpage = "https://sites.google.com/view/orbit-assist",
  abstract = {daptive interfaces can help users perform sequential decision-making tasks like robotic teleoperation given noisy, high-dimensional command signals (e.g., from a brain-computer interface). Recent advances in human-in-the-loop machine learning enable such systems to improve by interacting with users, but tend to be limited by the amount of data that they can collect from individual users in practice. In this paper, we propose a reinforcement learning algorithm to address this by training an interface to map raw command signals to actions using a combination of offline pre-training and online fine-tuning. To address the challenges posed by noisy command signals and sparse rewards, we develop a novel method for representing and inferring the user's long-term intent for a given trajectory. We primarily evaluate our method's ability to assist users who can only communicate through noisy, high-dimensional input channels through a user study in which 12 participants performed a simulated navigation task by using their eye gaze to modulate a 128-dimensional command signal from their webcam. The results show that our method enables successful goal navigation more often than a baseline directional interface, by learning to denoise user commands signals and provide shared autonomy assistance. We further evaluate on a simulated Sawyer pushing task with eye gaze control, and the Lunar Lander game with simulated user commands, and find that our method improves over baseline interfaces in these domains as well. Extensive ablation experiments with simulated user commands empirically motivate each component of our method.},
  url={https://ieeexplore.ieee.org/abstract/document/10341779},
  image={/img/papers/orbit.png}
}


@article{kim2023torque,
  author={Kim, Donghyeon and Glen Berseth and Schwartz, Mathew and Park, Jaeheung},
  journal={IEEE Robotics and Automation Letters}, 
  title={Torque-based Deep Reinforcement Learning for Task-and-Robot Agnostic Learning on Bipedal Robots Using Sim-to-Real Transfer}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={In this paper, we review the question of which action space is best suited for controlling a real biped robot in combination with Sim2Real training. Position control has been popular as it has been shown to be more sample efficient and intuitive to combine with other planning algorithms. However, for position control, gain tuning is required to achieve the best possible policy performance. We show that, instead, using a torque-based action space enables task-and-robot agnostic learning with less parameter tuning and mitigates the sim-to-reality gap by taking advantage of torque control's inherent compliance. Also, we accelerate the torque-based-policy training process by pre-training the policy to remain upright by compensating for gravity. The paper showcases the first successful sim-to-real transfer of a torque-based deep reinforcement learning policy on a real human-sized biped robot.},
  keywords={},
  arxiv={2304.09434},
  video={https://www.youtube.com/watch?v=CR6pTS39VRE},
  doi={10.1109/LRA.2023.3304561},
  ISSN={2377-3766},
  month={},
  image={/img/papers/tocabi.png},}

@inproceedings{
	li2023robust,
	author={Zhongyu Li and Xue Bin Peng and Pieter Abbeel and Sergey Levine and Glen Berseth and Koushil Sreenath},
	editor={Kostas E. Bekris and Kris Hauser and Sylvia L. Herbert and Jingjin Yu},
	title={Robust and Versatile Bipedal Jumping Control through Reinforcement Learning},
	booktitle={Robotics: Science and Systems XIX, Daegu, Republic of Korea, July 10-14, 2023},
	year={2023},
	url={https://doi.org/10.15607/RSS.2023.XIX.052},
	doi={10.15607/RSS.2023.XIX.052},
    arxiv={2302.09450},
    video={https://youtu.be/aAPSZ2QFB-E},
    image={/img/papers/cassiejump.png}
}

@inproceedings{quadsoccer,
  author    = {Yandong Ji and Zhongyu Li* and Yinan Sun and Xue Bin Peng and Sergey Levine and Glen Berseth and Koushil Sreenath},
  title     = {Hierarchical Reinforcement Learning for Precise Soccer Shooting Skills using a Quadrupedal Robot },
  booktitle = {Proc. IEEE/RSJ Intl Conf on Intelligent Robots and Systems (IROS 2022)},
  arxiv = {2208.01160},
  image = {/img/papers/a-reinforcement-learni-1.jpg},
  video = {https://www.youtube.com/watch?v=bteipHcJ8BM},
  abstract = {We address the problem of enabling quadrupedal robots to perform precise shooting skills in the real world using reinforcement learning. Developing algorithms to enable a legged robot to shoot a soccer ball to a given target is a challenging problem that combines robot motion control and planning into one task. To solve this problem, we need to consider the dynamics limitation and motion stability during the control of a dynamic legged robot. Moreover, we need to consider motion planning to shoot the hard-to-model deformable ball rolling on the ground with uncertain friction to a desired location. In this paper, we propose a hierarchical framework that leverages deep reinforcement learning to train (a) a robust motion control policy that can track arbitrary motions and (b) a planning policy to decide the desired kicking motion to shoot a soccer ball to a target. We deploy the proposed framework on an A1 quadrupedal robot and enable it to accurately shoot the ball to random targets in the real world. },
  year={2022}
}

@article{Traboco2022,
  title={AnyMorph: Learning Transferable Policies By Inferring Agent Morphology},
  author={Brandon Trabucco and Phielipp Mariano and Glen Berseth},
  journal   = {Internation Conference on Machine Learning},
  arxiv = {2206.12279},
  image = {/img/papers/anymorph_prompt.gif},
  projectpage = {https://mila.quebec/en/article/anymorph-learning-transferable-policies-by-inferring-agent-morphology/},
  abstract = {The prototypical approach to reinforcement learning involves training policies tailored to a particular agent from scratch for every new morphology. Recent work aims to eliminate the re-training of policies by investigating whether a morphology-agnostic policy, trained on a diverse set of agents with similar task objectives, can be transferred to new agents with unseen morphologies without re-training. This is a challenging problem that required previous approaches to use hand-designed descriptions of the new agent's morphology. Instead of hand-designing this description, we propose a data-driven method that learns a representation of morphology directly from the reinforcement learning objective. Ours is the first reinforcement learning algorithm that can train a policy to generalize to new agent morphologies without requiring a description of the agent's morphology in advance. We evaluate our approach on the standard benchmark for agent-agnostic control, and improve over the current state of the art in zero-shot generalization to new agents. Importantly, our method attains good performance without an explicit description of morphology. },
  year={2022}
}

@article{fickinger2021explore,
  title={Explore and Control with Adversarial Surprise},
  author={Fickinger, Arnaud and Jaques, Natasha and Parajuli, Samyak and Chang, Michael and Rhinehart, Nicholas and Glen Berseth and Russell, Stuart and Levine, Sergey},
  arxiv = {2107.07394},
  image = {/img/papers/eac.png},
  projectpage = {https://sites.google.com/view/adversarial-surprise/home},
  video = {https://youtu.be/ipSd1_txOr8},
  journal   = {CoRR},
  volume    = {abs/2107.07394},
  year      = {2021},
  url       = {https://arxiv.org/abs/2107.07394},
  eprinttype = {arXiv},
  eprint    = {2107.07394},
  timestamp = {Wed, 21 Jul 2021 15:55:35 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2107-07394.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
rhinehart2021intrinsic,
title={Information is Power: Intrinsic Control via Information Capture},
author={Nicholas Rhinehart and Jenny Wang and Glen Berseth and John D Co-Reyes and Danijar Hafner and Chelsea Finn and Sergey Levine},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=MO76tBOz9RL},
ArXiv={2112.03899}
}


@article{x2text,
  title={X2T: Training an X-to-Text Typing Interface with Online Learning from Implicit Feedback},
  author={Jensen Gao and Sid Reddy and Glen Berseth and Anca Dragon and Sergey Levine},
  journal={International Conference on Learning Representations (ICLR) 2021},
  year      = {2020},

}

@inproceedings{
co-reyes2021accelerating,
title={Accelerating Online Reinforcement Learning via Model-Based Meta-Learning},
author={John D Co-Reyes and Sarah Feng and Glen Berseth and Jie Qui and Sergey Levine},
booktitle={Learning to Learn - Workshop at ICLR 2021},
year={2021},
url={https://openreview.net/forum?id=XCJ5PEkuMkC},
}

@article{disco,
  title={DisCo RL: Distribution-Conditioned Reinforcement Learning for General-Purpose Policies},
  author={Soroush Nasiriany and   Vitchyr H. Pong and  Ashvin Nair and  Alexander Khazatsky and Glen Berseth and  Sergey Levine},
  journal={International Conference on Robotics and Automation (ICRA 2021)},
  year      = {2021},
  url = {https://ieeexplore.ieee.org/document/9561402},
  arxiv={2104.11707},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  projectpage={https://sites.google.com/view/disco-rl},
}

@inproceedings{realmm,
  title={Fully Autonomous Real-World Reinforcement Learning with Applications to Mobile Manipulation},
  author={Charles Sun and Coline Devin and Brian Yang and Jędrzej Orbik and Abhishek Gupta and Glen Berseth and Sergey Levine},
 booktitle = {Conference on Robot Learning (CoRL)},
	series = {CoRL '21},
	year = {2021},
	keywords = {Robotics, Deep Reinforcement Learning, Autonomous Learning},
	video= {https://youtu.be/PcYJoCe4Kr4},
}

@article{asha,
  title={ASHA: Assistive Teleoperation via Human-in-the-Loop Reinforcement Learning},
  author={Sean Chen* and Jensen Gao* and Siddharth Reddy and Glen Berseth and Anca D. Dragan and Sergey Levine},
  journal={IEEE International Conference on Robotics and Automation (ICRA)},
  year      = {2022},
  url={https://dl.acm.org/doi/abs/10.1109/ICRA46639.2022.9812442},
  arxiv = {2202.02465v1},
  image = {/img/papers/asha.png},
  projectpage = {https://sites.google.com/view/asha-assist},
  video = {https://drive.google.com/file/d/1PlnR1o-wa-0XGWwK_4j7TR7YeED8xhKV/view?usp=sharing},
  code = {https://github.com/rddy/asha},
  
}

@article{robustCassie,
  title={Reinforcement Learning for Robust Parameterized Locomotion Control of Bipedal Robots},
  author={Zhongyu Li and Xuxin Cheng and Xue Bin Peng and Pieter Abbeel and Sergey Levine and Glen Berseth and Koushil Sreenath},
  journal={International Conference on Robotics and Automation (ICRA 2021)},
  year      = {2020},

}

@inproceedings{
berseth2022comps,
title={Co{MPS}: Continual Meta Policy Search},
author={Glen Berseth and Zhiwei Zhang and Grace Zhang and Chelsea Finn and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=PVJ6j87gOHz},
arxiv = {2208.01160},
  
  projectpage = {https://sites.google.com/view/compspaper/home},
  video = {https://youtu.be/IAH_qFIQxxc},
code = {https://github.com/Neo-X/COMPS_public},
}

@article{coreyes2020ecological,
  author    = {John D. Co{-}Reyes and               Suvansh Sanjeev and               Glen Berseth and               Abhishek Gupta and               Sergey Levine},
  title     = {Ecological Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/2006.12478},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.12478},
  eprinttype = {arXiv},
  eprint    = {2006.12478},
  timestamp = {Tue, 23 Jun 2020 17:57:22 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-12478.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},

}

@inproceedings{berseth2021smirl,
    title={SMiRL: Surprise Minimizing Reinforcement Learning in Unstable Environments},
    author={Glen Berseth and Daniel Geng and Coline Manon Devin and Nicholas Rhinehart and Chelsea Finn and Dinesh Jayaraman and Sergey Levine},
    booktitle={International Conference on Learning Representations \textbf{(Oral, top 1.8\% of submissions)}},
    year={2021},
    url={https://openreview.net/forum?id=cPZOyoDloxl},
    video={https://youtu.be/ps0dsFXQszQ},
    projectpage={https://sites.google.com/view/surpriseminimization},
    arxiv={1912.05510},
}

@article{8964083,
  title={Gamification of Crowd-Driven Environment Design},
  author={Haworth, Michael Brandon and Usman, Muhammad and Schaumann, Davide and Chakraborty, Nilay and Berseth Glen and Faloutsos, Petros and Kapadia, Mubbasir},
  journal={IEEE Computer Graphics and Applications},
  year={2020},
  publisher={IEEE},

}

@article{MAVRC,
  title={Morphology-Agnostic Visual Robotic Control},
  author={Yang, Brian and Jayaraman, Dinesh and Berseth Glen and Efros, Alexei and Levine, Sergey},
  journal={IEEE Robotics and Automation Letters},
  volume={5},
  number={2},
  pages={766--773},
  year={2020},
  publisher={IEEE},

}

@inproceedings{CC-RIG,
	author = {Ashvin Nair$^*$ and Shikhar Bahl$^*$ and Alexander Khazatsky$^*$ and Vitchyr Pong and Glen Berseth and Sergey Levine},
	title = {Contextual Imagined Goals for Self-Supervised Robotic Learning},
	booktitle = {Conference on Robot Learning (CoRL)},
	series = {CoRL '19},
	year = {2019},
	location = {Osaka, Japan},
	keywords = {Robotics, Deep Reinforcement Learning, Self-Supervision},
	arxiv = {2208.01160},
  
  projectpage = {https://mila.quebec/en/article/anymorph-learning-transferable-policies-by-inferring-agent-morphology/},
  video = {https://www.youtube.com/watch?v=bteipHcJ8BM},
} 

@article{8013477,
  title={Evaluating and optimizing evacuation plans for crowd egress},
  author={Cassol, Vincius J and Testa, Est{\^e}v{\~a}o Smania and Jung, Cl{\'a}udio Rosito and Usman, Muhammad and Faloutsos, Petros and Berseth Glen and Kapadia, Mubbasir and Badler, Norman I and Musse, Soraia Raupp},
  journal={IEEE computer graphics and applications},
  volume={37},
  number={4},
  pages={60--71},
  year={2017},
  publisher={IEEE},

}


@ARTICLE{Berseth2023-tn,
  title     = "Towards Learning to Imitate from a Single Video Demonstration",
  author    = "Berseth, Glen and Golemo, Florian and Pal, Christopher",
  abstract  = "Agents that can learn to imitate behaviours observed in
               video--without having direct access to internal state or action
               information of the observed agent--are more suitable for
               learning in …",
  journal   = "J. Mach. Learn. Res.",
  publisher = "jmlr.org",
  volume    =  24,
  number    =  78,
  pages     = "1--26",
  year      =  2023,
  url       = {https://www.jmlr.org/papers/v24/21-1174.html},
  image = {/img/papers/virl.png},
  video={https://youtu.be/B93_B7tBTc0},
  projectpage={https://neo-x.github.io/blog/2019/05/25/VizImitation.html},
  html={https://sites.google.com/view/virl1},
}

@article{CHER,
  author    = {Abdul Rahman Kreidieh and Glen Berseth and Brandon Traboco Samyak Parajuli and               Sergey Levine and               Alexandre M. Bayen},
  title     = {Inter-Level Cooperation in Hierarchical Reinforcement Learning},
  journal   = {Under submission to Journal of Machine Learning Research},
  arxiv={1912.02368},
  year={Preprint},
  image = {/img/papers/CHER.png},
}

@article{terrainRLSim,
  author    = {Glen Berseth and
               Xue Bin Peng and
               Michiel van de Panne},
  title     = {Terrain {RL} Simulator},
  journal   = {CoRR},
  volume    = {abs/1804.06424},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.06424},
  archivePrefix = {arXiv},
  eprint    = {1804.06424},
  timestamp = {Mon, 13 Aug 2018 16:46:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1804-06424},
  bibsource = {dblp computer science bibliography, https://dblp.org},

}

@inproceedings{cassie,
  author    = {Zhaoming Xie and
               Glen Berseth and
               Patrick Clary and
               Jonathan W. Hurst and
               Michiel van de Panne},
  title     = {Feedback Control For Cassie With Deep Reinforcement Learning},
  booktitle = {Proc. IEEE/RSJ Intl Conf on Intelligent Robots and Systems (IROS 2018)},
  year={2018},

}

@inproceedings{MBAE,
  title={Model-Based Action Exploration for Learning Dynamic Motion Skills},
  author={Glen Berseth and Alex Kyriazis and Ivan Zinin and William Choi and Michiel van de Panne},
  booktitle = {Proc. IEEE/RSJ Intl Conf on Intelligent Robots and Systems (IROS 2018)},
  year={2018},
  video={https://youtu.be/yjomPyWZRhY},
}

@inproceedings{deepcrowds,
 author = {Berseth Glen * and Haworth*, Brandon and Kapadia, Mubbasir and Faloutsos, Petros},
 title = {Deep Integration of Physical Humanoid Control and Crowd Navigation (\textbf{best paper runner up})},
 booktitle = {Proceedings of the 13th International Conference on Motion in Games},
 series = {MIG '20},
 year = {2020},
 publisher = {ACM},
 address = {New York, NY, USA},

} 

@inproceedings{Usman:2017:PES:3136457.3136458,
 author = {Usman, Muhammad and Haworth, Brandon and Berseth Glen and Kapadia, Mubbasir and Faloutsos, Petros},
 title = {Perceptual Evaluation of Space in Virtual Environments},
 booktitle = {Proceedings of the Tenth International Conference on Motion in Games},
 series = {MIG '17},
 year = {2017},
 isbn = {978-1-4503-5541-4},
 location = {Barcelona, Spain},
 pages = {16:1--16:10},
 articleno = {16},
 numpages = {10},
 acmid = {3136458},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {architecture, navigation, perceptual study, spatial analysis, virtual reality},

} 

@inproceedings{Chakraborty:2017:CSC:3136457.3136463,
 author = {Chakraborty, Nilay and Haworth, Brandon and Usman, Muhammad and Berseth Glen and Faloutsos, Petros and Kapadia, Mubbasir},
 title = {Crowd Sourced Co-design of Floor Plans Using Simulation Guided Games},
 booktitle = {Proceedings of the Tenth International Conference on Motion in Games},
 series = {MIG '17},
 year = {2017},
 isbn = {978-1-4503-5541-4},
 location = {Barcelona, Spain},
 pages = {1:1--1:5},
 articleno = {1},
 numpages = {5},
 acmid = {3136463},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {architectural design, co-design, gamification},

} 

@article{density_flow_relationship,
  title={On density flow relationships during crowd evacuation},
  author={Haworth, Brandon and Usman, Muhammad and Berseth Glen and Kapadia, Mubbasir and Faloutsos, Petros},
  journal={Computer Animation and Virtual Worlds 28 (3-4)},
  year = {2017},

}


@article{PLAiD,
  title={Progressive Reinforcement Learning with Distillation for Multi-Skilled Motion Control},
  author={Glen Berseth and Cheng Xie and Paul Cernek and Michiel Van de Panne},
  journal={International Conference on Learning Representations (ICLR) 2018},
  year      = {2018},
  video={https://youtu.be/_DjHbHCXGk0},
}

@article{peng2017hikeRL,
  title={DeepLoco: Dynamic Locomotion Skills Using Hierarchical Deep Reinforcement Learning},
  author={Peng, Xue Bin and Berseth Glen and Yin, KangKang and van de Panne, Michiel},
  journal={SIGGRAPH 2017},
  year      = {2017},

}

@article{uDOME,
  author    = {Glen Berseth and Brandon Haworth and Muhammad Usman and Davide Schaumann and Mahyar Khayatkhoei and  Mubbasir Kapadia and Petros Faloutsos},
  title     = {Interactive Architectural Design with Diverse Solution Exploration},
  journal   = {IEEE Transactions on Visualization and Computer Graphics},
  year      = {2019},
  dio       = {10.1109/TVCG.2019.2938961},
  video={https://youtu.be/xtbln0XfBWA},
}

@inproceedings{usmanGI2017,
  title={Understanding spatial perception and visual modes in the review of architectural designs},
  author={Usman, Muhammad and Haworth, Brandon and Berseth Glen and Kapadia, Mubbasir and Faloutsos, Petros},
  booktitle={Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation, 31},
  year = {2017},

}

@article{berseth2016acclmesh,
  title={ACCLMesh: curvature-based navigation mesh generation},
  author={Berseth Glen and Kapadia, Mubbasir and Faloutsos, Petros},
  journal={Computer Animation and Virtual Worlds},
  volume={27},
  number={3-4},
  pages={195--204},
  year={2016},

}

@article{CODE2017,
  title={CODE: Crowd Optimized Design of Environments},
  author={Haworth, Brandon and Usman, Muhammad and Berseth Glen and Kapadia, Mubbasir and Faloutsos, Petros},
  journal={Computer Animation and Virtual Worlds},
  year={2017},

}


@article{peng2016terrain,
  title={Terrain-adaptive locomotion skills using deep reinforcement learning},
  author={Peng, Xue Bin and Berseth Glen and van de Panne, Michiel},
  journal={ACM Transactions on Graphics (TOG)},
  volume={35},
  number={4},
  pages={81},
  year={2016},
  publisher={ACM},

}

@inproceedings{haworth2016using,
  title={Using synthetic crowds to inform building pillar placements},
  author={Haworth, Brandon and Usman, Muhammad and Berseth Glen and Khayatkhoei, Mahyar and Kapadia, Mubbasir and Faloutsos, Petros},
  booktitle={Virtual Humans and Crowds for Immersive Environments (VHCIE), IEEE},
  pages={7--11},
  year={2016},
  organization={IEEE},

}

@article{Peng:2015:DTT:2809654.2766910,
 author = {Peng, Xue Bin and Berseth Glen and van de Panne, Michiel},
 title = {Dynamic Terrain Traversal Skills Using Reinforcement Learning},
 journal = {ACM Trans. Graph.},
 issue_date = {August 2015},
 volume = {34},
 number = {4},
 month = jul,
 year = {2015},
 pages = {80:1--80:11},
 articleno = {80},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/2766910},
 doi = {10.1145/2766910},
 acmid = {2766910},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {computer animation, physics simulation},

} 

@article {CAV:CAV1652,
author = {Berseth Glen and Usman, Muhammad and Haworth, Brandon and Kapadia, Mubbasir and Faloutsos, Petros},
title = {Environment optimization for crowd evacuation},
journal = {Computer Animation and Virtual Worlds},
volume = {26},
number = {3-4},
issn = {1546-427X},
url = {http://dx.doi.org/10.1002/cav.1652},
doi = {10.1002/cav.1652},
pages = {377--386},
keywords = {crowd simulation, optimization and analysis},
year = {2015},
abstract = {The layout of a building, real or virtual, affects the flow patterns of its intended users. It is well established, for example, that the placement of pillars at proper locations can often facilitate pedestrian flow during the evacuation of a building. Such considerations are therefore important for architects, game level developers, and others whose domains involve agents navigating through buildings. In this paper, we take the first steps towards developing a simulation framework that can be used to study the optimal placement of architectural elements, such as pillars or doors, for the purposes of facilitating dense pedestrian flow during the evacuation of a building. In particular, we show that the steering algorithms used to model the local navigation abilities of the agents significantly affect the results, which motivates the need for a statistically valid approach and further study. Copyright © 2015 John Wiley & Sons, Ltd.},
  video = {https://youtu.be/EEO35f1WV2k},
}

@inproceedings{Berseth:2014:COG:2668064.2668100,
 author = {Berseth Glen and Haworth, M. Brandon and Kapadia, Mubbasir and Faloutsos, Petros},
 title = {Characterizing and Optimizing Game Level Difficulty},
 booktitle = {Proceedings of the Seventh International Conference on Motion in Games},
 series = {MIG '14},
 year = {2014},
 isbn = {978-1-4503-2623-0},
 location = {Playa Vista, California},
 pages = {153--160},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2668084.2668100},
 doi = {10.1145/2668084.2668100},
 acmid = {2668100},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {game elements, optimization, procedural content generation, static analysis},

} 

@article {CASA2015:RobustFootsteps,
author = {Berseth Glen and Kapadia, Mubbasir and Faloutsos, Petros},
title = {Robust Space-Time Footsteps for Agent-Based Steering (best short paper)},
journal = {Computer Animation and Virtual Worlds},
isbn = {978-981-09-4946-4},
keywords = {Crowd Simulation, Footsteps, Planning and Analysis},
year = {2015},
abstract = {Recent agent-based steering methods abandon the standard particle abstraction of an agent's locomotion abilities and employ more complex models from timed footsteps to physics-based controllers. These models often provide the action space of an optimal search method that plans a sequence of steering actions for each agent that minimize a performance criterion. The transition from particle-based models to more complex models is not straightforward and gives rise to a number of technical challenges. For example, a disk geometry is constant, symmetric and convex, while a footstep model maybe non-convex and dynamic. In this paper, we identify general challenges associated with footstep-based steering approaches and present a new space-time footstep planning steering model that is robust to challenging scenario configurations.},
  video = {https://youtu.be/m7gfoeIzTSQ},
}

@inproceedings{SCA14:113-122:2014,
author = {Glen Berseth and Mubbasir Kapadia and Brandon Haworth and Petros Faloutsos },
title = {SteerFit: Automated Parameter Fitting for Steering Algorithms},
pages = {113-122},
url = {http://diglib.eg.org/EG/DL/WS/SCA/SCA14/113-122.pdf},
doi = {10.2312/sca.20141129},
abstract = {In the context of crowd simulation, there is a diverse set of algorithms that model steering. The performance of steering approaches, both in terms of quality of results and computational efficiency, depends on internal parameters that are manually tuned to satisfy application-specific requirements. This paper investigates the effect that these parameters have on an algorithm's performance. Using three representative steering algorithms and a set of established performance criteria, we perform a number of large scale optimization experiments that optimize an algorithm's parameters for a range of objectives. For example, our method automatically finds optimal parameters to minimize turbulence at bottlenecks, reduce building evacuation times, produce emergent patterns, and increase the computational efficiency of an algorithm. We also propose using the Pareto Optimal front as an efficient way of modelling optimal relationships between multiple objectives, and demonstrate its effectiveness by estimating optimal parameters for interactively defined combinations of the associated objectives. The proposed methodologies are general and can be applied to any steering algorithm using any set of performance criteria.},
	year= {2014},
	isbn = {978-3-905674-61-3},
	issn = {1727-5288},
	location = {Copenhagen, Denmark},
	publisher = {Eurographics Association},
	journal = {Eurographics/ ACM SIGGRAPH Symposium on Computer Animation},
	booktitle = {Eurographics/ ACM SIGGRAPH Symposium on Computer Animation},
}

@inproceedings{Berseth:2015:ACN:2822013.2822043,
 author = {Berseth Glen and Kapadia, Mubbasir and Faloutsos, Petros},
 title = {ACCLMesh: Curvature-based Navigation Mesh Generation},
 booktitle = {Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games},
 series = {MIG '15},
 year = {2015},
 isbn = {978-1-4503-3991-9},
 location = {Paris, France},
 pages = {97--102},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2822013.2822043},
 doi = {10.1145/2822013.2822043},
 acmid = {2822043},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {crowd simulation, curvature, navigation mesh},

} 

@inproceedings{Haworth:2015:EOL:2822013.2822040,
 author = {Haworth, Brandon and Usman, Muhammad and Berseth Glen and Kapadia, Mubbasir and Faloutsos, Petros},
 title = {Evaluating and Optimizing Level of Service for Crowd Evacuations},
 booktitle = {Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games},
 series = {MIG '15},
 year = {2015},
 isbn = {978-1-4503-3991-9},
 location = {Paris, France},
 pages = {91--96},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2822013.2822040},
 doi = {10.1145/2822013.2822040},
 acmid = {2822040},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {crowd evacuation, crowd simulation, environment optimization, level of service, steering algorithms},

} 

@inproceedings{Berseth:2013:SES:2522628.2522650,
author = {Berseth Glen and Kapadia, Mubbasir and Faloutsos, Petros},
title = {SteerPlex: Estimating Scenario Complexity for Simulated Crowds},
booktitle = {Proceedings of Motion on Games},
series = {MIG '13},
year = {2013},
isbn = {978-1-4503-2546-2},
location = {Dublin 2, Ireland},
pages = {45:67--45:76},
articleno = {45},
numpages = {10},
url = {http://doi.acm.org/10.1145/2522628.2522650},
doi = {10.1145/2522628.2522650},
acmid = {2522650},
publisher = {ACM},
address = {New York, NY, USA},
keywords = {crowd analysis, crowd simulation, scenario complexity},
} 

@inproceedings{codeLBW,
 author = {Haworth, Brandon and Usman, Muhammad and Berseth Glen and Khayatkhoei, Mahyar and Kapadia, Mubbasir and Faloutsos, Petros},
 title = {Towards Computer Assisted Crowd Aware Architectural Design},
 booktitle = {CHI '16 Extended Abstracts},
 series = {CHI EA '16},
 year = {2016},
 isbn = {978-1-4503-2474-8},
 location = {San Jose, CA, USA},
 pages = {2287--2292},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2559206.2581174},
 doi = {10.1145/2559206.2581174},
 acmid = {2581174},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Architectural Optimization, User-in-the-loop design, Crowd
 Simulation},

} 

